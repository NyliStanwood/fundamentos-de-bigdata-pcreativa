## SPARK Flight Predictor

use the spark image
https://hub.docker.com/r/apache/spark/

to have java 8 configured

ENV JAVA_HOME
ENV JDK_HOME
ENV PATH=$JAVA_HOME/bin:$PATH

to have Spark 3.5.3 and configure the
ENV SPARK_HOME

copy the current repository files into the container.

to run the code

cd /practica_creativa/flight_prediction

spark-submit \
 --class es.upm.dit.ging.predictor.MakePrediction \
 --master local[*] \
 --packages org.mongodb.spark:mongo-spark-connector_2.12:10.4.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 \
 target/scala-2.12/flight_prediction_2.12-0.1.jar

docker-compose to start the container and
should share the /models that was created by this

```
services:
  {...}
  training:
    build:
      context: .
      dockerfile: Dockerfile.training
    container_name: ml-training
```

spark-submit connects to mongo service, make sure it can connect ej:

MONGO_HOST=${MONGO_HOST:-mongo}
MONGO_PORT=${MONGO_PORT:-27017}
MONGO_USER=${MONGO_USER:-}
MONGO_PASS=${MONGO_PASS:-}
//MONGO_INITDB_ROOT_USERNAME: root
//MONGO_INITDB_ROOT_PASSWORD: example
MONGO_AUTH_DB=${MONGO_AUTH_DB:-admin}

mongodb://${MONGO_HOST}:${MONGO_PORT}/${MONGO_DB}" ${MONGO_USER:+--username} ${MONGO_USER:+"${MONGO_USER}"} ${MONGO_PASS:+--password} ${MONGO_PASS:+"${MONGO_PASS}"}

docker-compose down
docker-compose up -d --build
docker-compose logs -f sparksubmit
