services:
  kafka:
    image: apache/kafka:3.9.0
    container_name: kafka-server
    ports:
      - "9092:9092"
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "1.0"
    mem_limit: "1g"
    pids_limit: 1024
    environment:
      KAFKA_NODE_ID: 1 #Unique identifier for this node in the KRaft cluster
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_PROCESS_ROLES: "broker,controller" #Define the roles of this node
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093" #Define the controller quorum voters
      KAFKA_LISTENERS: "PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER" #Define the listener names for the controller
    networks:
      - flight-network

  ##create Kafka topic for flight-delay-ml-request in --bootstrap-server kafka:9092 before dying
  kafka-init:
    image: apache/kafka:3.9.0
    container_name: kafka-init
    depends_on:
      - kafka
    entrypoint: /bin/sh
    command: -c "sleep 10 && /opt/kafka/bin/kafka-topics.sh --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic flight-delay-ml-request --if-not-exists"
    restart: on-failure
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "2"
    cpus: "0.25"
    mem_limit: "256m"
    pids_limit: 256
    networks:
      - flight-network

  mongo:
    build:
      context: .
      dockerfile: Dockerfile.mongo
    image: mongo-custom:7.0
    container_name: mongo
    ports:
      - "27017:27017"
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "1.5"
    mem_limit: "2g"
    pids_limit: 2048
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    volumes:
      - mongo_data:/data/db
      - ./resources:/resources
    networks:
      - flight-network

  training:
    build:
      context: .
      dockerfile: Dockerfile.training
    container_name: ml-training
    restart: on-failure
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "1.0"
    mem_limit: "2g"
    pids_limit: 1024
    volumes:
      - ./resources:/resources
      - ./data:/data
      - ./models:/models
    networks:
      - flight-network

  # Spark Master
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark-master
    image: spark-master:3.5.3
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "1.0"
    mem_limit: "1g"
    pids_limit: 1024
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
    networks:
      - flight-network

  # Spark Worker 1
  spark-worker-1:
    build:
      context: .
      dockerfile: Dockerfile.spark-worker
    image: spark-worker-1:3.5.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "1.0"
    mem_limit: "2g"
    pids_limit: 2048
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_WORKER_CORES: "1"
      SPARK_WORKER_MEMORY: "1g"
    volumes:
      - ./models:/practica_creativa/models
    networks:
      - flight-network

  # Spark Worker 2
  spark-worker-2:
    build:
      context: .
      dockerfile: Dockerfile.spark-worker
    image: spark-worker-2:3.5.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "1.0"
    mem_limit: "2g"
    pids_limit: 2048
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_WORKER_CORES: "1"
      SPARK_WORKER_MEMORY: "1g"
    volumes:
      - ./models:/practica_creativa/models
    networks:
      - flight-network

  sparksubmit:
    build:
      context: .
      dockerfile: Dockerfile.sparksubmit
    container_name: sparksubmit
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - mongo
      - kafka
    restart: on-failure
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "1.0"
    mem_limit: "1g"
    pids_limit: 1024
    environment:
      SPARK_MASTER_URL: spark://spark-master:7077
      MONGO_HOST: mongo
      MONGO_PORT: 27017
      MONGO_USER: root
      MONGO_PASS: example
      MONGO_AUTH_DB: admin
      MONGO_DB: agile_data_science
    volumes:
      - ./models:/practica_creativa/models
    networks:
      - flight-network

  flask:
    image: python:3.9
    container_name: flask-app
    depends_on:
      - mongo
      - kafka
      - kafka-init
    working_dir: /resources/web
    environment:
      PROJECT_HOME: /resources
    volumes:
      - ./resources:/resources
    ports:
      - "5001:5001"
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    cpus: "0.5"
    mem_limit: "512m"
    pids_limit: 512
    command: >
      sh -c "sleep 25 &&
             pip install -r /resources/requirements.txt &&
             python predict_flask.py"
    networks:
      - flight-network

networks:
  flight-network:
    driver: bridge

volumes:
  mongo_data:
